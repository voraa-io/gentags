# Results Directory

## Overview

This directory contains output from gentag extraction experiments. Most results are gitignored to avoid committing large files or sensitive data.

## Structure

```
results/
├── README.md          # This file
├── meta/              # Metadata files (public-safe)
│   └── [manifest files]
├── examples/           # Small example outputs (optional)
│   └── [example files]
├── raw/               # Raw model responses (gitignored)
│   └── [error responses]
└── [timestamped CSV files]  # Main results (gitignored)
```

## Output Format

### Main Results CSV

Results are saved as CSV files with naming convention:

```
gentags_YYYYMMDD_HHMMSS.csv
phase1_YYYYMMDD_HHMMSS.csv
```

**Columns:**

- `run_id`: Unique run identifier
- `venue_id`: Venue identifier
- `venue_name`: Venue name
- `model`: Model name used
- `prompt_type`: Prompt type used
- `run_number`: Run number (1, 2, ...)
- `exp_id`: Experiment identifier
- `timestamp`: Extraction timestamp
- `tag_raw`: Raw extracted tag
- `tag_norm`: Normalized tag (for matching)
- `tag_norm_eval`: Strictly normalized tag (for stability metrics)
- `word_count`: Number of words in tag
- `num_reviews`: Number of reviews for venue
- `reviews_total_chars`: Total characters in reviews
- `time_seconds`: Extraction time
- `input_tokens`: Input token count
- `output_tokens`: Output token count
- `total_tokens`: Total token count
- `cost_usd`: Estimated cost in USD
- `status`: Extraction status ("success", "parse_error", "error")
- `prompt_hash`: Hash of prompt version
- `system_prompt_hash`: Hash of system prompt
- `input_prompt_hash`: Hash of exact prompt sent
- `tags_filtered_count`: Number of tags filtered out
- `extraction_phase`: Phase identifier ("phase1")

### Raw Responses

Raw model responses are saved in `results/raw/` for:

- Debugging parse errors
- Auditing model outputs
- Error analysis

**Naming:** `{exp_id}_{run_id}.txt`

### Extraction-Level CSV (from summarize_cost)

Use `summarize_cost()` to generate extraction-level CSVs (one row per extraction):

```python
from gentags import summarize_cost, load_results

df = load_results("results/gentags_20250117_120000.csv")
summary = summarize_cost(df)

# Save extraction-level CSV
summary["extractions"].to_csv("results/extractions_20250117.csv", index=False)

# Save cost breakdown by model/prompt
summary["by_model_prompt"].to_csv("results/cost_by_model_prompt_20250117.csv", index=False)
```

**Extraction-level columns:**

- All metadata columns (run_id, exp_id, venue_id, model, prompt_type, etc.)
- `n_tags`: Number of tags extracted
- `n_unique_tag_eval`: Number of unique tags (after eval normalization)
- `cost_per_tag`: Cost per tag
- `cost_per_unique_tag`: Cost per unique tag

### Metadata Files (Manifests)

Manifest files in `results/meta/` are JSON files containing:

- **Git info:** commit hash, branch, dirty status
- **System info:** Python version, OS, platform
- **Pipeline info:** pipeline version, prompt/model hashes and versions
- **Dependencies:** Poetry lock hash
- **Dataset info:** name, path, row count, filters applied

**Naming:** `manifest_YYYYMMDD_HHMMSS.json`

**Generated by:** `scripts/generate_manifest.py`

## Usage

### Loading Results

```python
from gentags import load_results, summarize_cost

# Load main results (one row per tag)
df = load_results("results/gentags_20250117_120000.csv")

# Filter to successful extractions
df_success = df[df['status'] == 'success']
df_tags = df_success[df_success['tag_raw'].notna()]
```

### Cost Analysis

```python
# Generate cost summary
summary = summarize_cost(df)

# Access totals
print(f"Total cost: ${summary['total_cost_usd']:.6f}")
print(f"Avg cost per extraction: ${summary['avg_cost_per_extraction_usd']:.6f}")
print(f"Avg cost per tag: ${summary['avg_cost_per_tag_usd']:.6f}")

# Access extraction-level data (one row per extraction)
extractions = summary["extractions"]

# Access cost breakdown by model/prompt
by_model_prompt = summary["by_model_prompt"]
```

## Analysis

See notebooks for analysis:

- `notebooks/02_phase1_analysis.ipynb`: Stability analysis
- `notebooks/03_reconstruction_eval.ipynb`: Reconstruction evaluation

## Gitignore

The following are gitignored:

- `*.csv` (main results files)
- `raw/` (raw responses)
- Large output files

The following are committed:

- `README.md` (this file)
- `meta/` (metadata, if public-safe)
- `examples/` (small examples, if included)
